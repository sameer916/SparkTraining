{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managed Tables - Exercise\n",
    "\n",
    "Let us use NYSE data and see how we can create tables in Spark Metastore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Ag7tkdhewcM?rel=0&amp;controls=1&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Ag7tkdhewcM?rel=0&amp;controls=1&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start spark context for this Notebook so that we can execute the code provided. You can sign up for our [10 node state of the art cluster/labs](https://labs.itversity.com/plans) to learn Spark SQL using our unique integrated LMS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "username = itv001477\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "itv001477"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val username = System.getProperty(\"user.name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "username = itv001477\n",
       "spark = org.apache.spark.sql.SparkSession@2d988ea\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SparkSession@2d988ea"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "\n",
    "val username = System.getProperty(\"user.name\")\n",
    "val spark = SparkSession.\n",
    "    builder.\n",
    "    config(\"spark.ui.port\", \"0\").\n",
    "    config(\"spark.sql.warehouse.dir\", s\"/user/${username}/warehouse\").\n",
    "    enableHiveSupport.\n",
    "    appName(s\"${username} | Spark SQL - Managing Tables - Basic DDL and DML\").\n",
    "    master(\"yarn\").\n",
    "    getOrCreate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are going to use CLIs, you can use Spark SQL using one of the 3 approaches.\n",
    "\n",
    "**Using Spark SQL**\n",
    "\n",
    "```\n",
    "spark2-sql \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```\n",
    "\n",
    "**Using Scala**\n",
    "\n",
    "```\n",
    "spark2-shell \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```\n",
    "\n",
    "**Using Pyspark**\n",
    "\n",
    "```\n",
    "pyspark2 \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Duration: **30 Minutes**\n",
    "* Data Location (Local): /data/nyse_all/nyse_data\n",
    "* Create a database with the name - YOUR_OS_USER_NAME_nyse\n",
    "* Table Name: nyse_eod\n",
    "* File Format: TEXTFILE (default)\n",
    "* Review the files by running Linux commands before using data sets. Data is compressed and we can load the files as is.\n",
    "* Copy one of the zip file to your home directory and preview the data. There should be 7 fields. You need to determine the delimiter.\n",
    "* Field Names: stockticker, tradedate, openprice, highprice, lowprice, closeprice, volume. For example, you need to use `BIGINT` for volume not `INT`.\n",
    "* Determine correct data types based on the values\n",
    "* Create Managed table with default Delimiter.\n",
    "> As delimiters in data and table are not same, you need to figure out how to get data into the target table.\n",
    "* Make sure the data is copied into the table as per the structure defined and validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Waiting for a Spark session to start..."
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++\n",
       "\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "CREATE DATABASE itv001477_nyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Waiting for a Spark session to start..."
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++\n",
       "\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "USE itv001477_nyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++\n",
       "\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "DROP TABLE nyse_eod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++\n",
       "\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "CREATE TABLE nyse_eod(\n",
    "    stockticker STRING, \n",
    "    tradedate INT, \n",
    "    openprice DOUBLE, \n",
    "    highprice DOUBLE, \n",
    "    lowprice DOUBLE, \n",
    "    closeprice DOUBLE, \n",
    "    volume BIGINT\n",
    ") ROW FORMAT DELIMITED FIELDS TERMINATED BY ','"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++\n",
       "\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "LOAD DATA LOCAL INPATH '/home/${username}/NYSE_dataFiles/NYSE_*.txt' INTO TABLE nyse_eod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "\n",
    "val username = System.getProperty(\"user.name\")\n",
    "val spark = SparkSession.\n",
    "    builder.\n",
    "    config(\"spark.ui.port\", \"0\").\n",
    "    config(\"spark.sql.warehouse.dir\", s\"/user/${username}/warehouse\").\n",
    "    enableHiveSupport.\n",
    "    appName(s\"${username} | Spark SQL - Managing Tables - Basic DDL and DML\").\n",
    "    master(\"yarn\").\n",
    "    getOrCreate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are going to use CLIs, you can use Spark SQL using one of the 3 approaches.\n",
    "\n",
    "**Using Spark SQL**\n",
    "\n",
    "```\n",
    "spark2-sql \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```\n",
    "\n",
    "**Using Scala**\n",
    "\n",
    "```\n",
    "spark2-shell \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```\n",
    "\n",
    "**Using Pyspark**\n",
    "\n",
    "```\n",
    "pyspark2 \\\n",
    "    --master yarn \\\n",
    "    --conf spark.ui.port=0 \\\n",
    "    --conf spark.sql.warehouse.dir=/user/${USER}/warehouse\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation\n",
    "\n",
    "Run the following queries to ensure that you will be able to read the data.\n",
    "\n",
    "```\n",
    "DESCRIBE FORMATTED YOUR_OS_USER_NAME_nyse.nyse_eod;\n",
    "SELECT * FROM YOUR_OS_USER_NAME_nyse.nyse_eod LIMIT 10\n",
    "SELECT count(1) FROM YOUR_OS_USER_NAME_nyse.nyse_eod;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+-------------------------------------------------------------------------+-------+\n",
      "|col_name                    |data_type                                                                |comment|\n",
      "+----------------------------+-------------------------------------------------------------------------+-------+\n",
      "|stockticker                 |string                                                                   |null   |\n",
      "|tradedate                   |string                                                                   |null   |\n",
      "|openprice                   |double                                                                   |null   |\n",
      "|highprice                   |double                                                                   |null   |\n",
      "|lowprice                    |double                                                                   |null   |\n",
      "|closeprice                  |double                                                                   |null   |\n",
      "|volume                      |bigint                                                                   |null   |\n",
      "|                            |                                                                         |       |\n",
      "|# Detailed Table Information|                                                                         |       |\n",
      "|Database                    |itversity_nyse                                                           |       |\n",
      "|Table                       |nyse_eod                                                                 |       |\n",
      "|Owner                       |itv000242                                                                |       |\n",
      "|Created Time                |Mon May 17 07:03:49 EDT 2021                                             |       |\n",
      "|Last Access                 |Wed Dec 31 19:00:00 EST 1969                                             |       |\n",
      "|Created By                  |Spark 2.4.7                                                              |       |\n",
      "|Type                        |MANAGED                                                                  |       |\n",
      "|Provider                    |hive                                                                     |       |\n",
      "|Table Properties            |[transient_lastDdlTime=1621249494, STATS_GENERATED_VIA_STATS_TASK=true]  |       |\n",
      "|Statistics                  |139239940 bytes                                                          |       |\n",
      "|Location                    |hdfs://m01.itversity.com:9000/user/itv000242/itv000242/warehouse/nyse_eod|       |\n",
      "|Serde Library               |org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe                       |       |\n",
      "|InputFormat                 |org.apache.hadoop.mapred.TextInputFormat                                 |       |\n",
      "|OutputFormat                |org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat               |       |\n",
      "|Storage Properties          |[field.delim=,, serialization.format=,]                                  |       |\n",
      "|Partition Provider          |Catalog                                                                  |       |\n",
      "+----------------------------+-------------------------------------------------------------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// There should not be field delimiter as the requirement is to use default delimiter\n",
    "spark.sql(\"DESCRIBE FORMATTED itversity_nyse.nyse_eod\").show(200, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "|      ...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "source": "user"
    },
    {
     "data": {
      "text/plain": [
       "+-----------+---------+---------+---------+--------+----------+------+\n",
       "|stockticker|tradedate|openprice|highprice|lowprice|closeprice|volume|\n",
       "+-----------+---------+---------+---------+--------+----------+------+\n",
       "|         AA| 19980101|    52.77|    52.77|   52.77|     52.77|     0|\n",
       "|        ABC| 19980101|     7.28|     7.28|    7.28|      7.28|     0|\n",
       "|        ABM| 19980101|    15.28|    15.28|   15.28|     15.28|     0|\n",
       "|        ABT| 19980101|    32.75|    32.75|   32.75|     32.75|     0|\n",
       "|        ABX| 19980101|    18.62|    18.62|   18.62|     18.62|     0|\n",
       "|        ACP| 19980101|     9.75|     9.75|    9.75|      9.75|     0|\n",
       "|        ACV| 19980101|    21.37|    21.37|   21.37|     21.37|     0|\n",
       "|        ADC| 19980101|    21.75|    21.75|   21.75|     21.75|     0|\n",
       "|        ADM| 19980101|    17.84|    17.84|   17.84|     17.84|     0|\n",
       "|        ADX| 19980101|    16.12|    16.12|   16.12|     16.12|     0|\n",
       "+-----------+---------+---------+---------+--------+----------+------+\n",
       "\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT * FROM itv001477_nyse.nyse_eod LIMIT 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+--------+\n",
       "|count(1)|\n",
       "+--------+\n",
       "| 9384739|\n",
       "+--------+\n",
       "\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT count(1) FROM itv001477_nyse.nyse_eod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark 2 - Scala",
   "language": "scala",
   "name": "spark_2_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
